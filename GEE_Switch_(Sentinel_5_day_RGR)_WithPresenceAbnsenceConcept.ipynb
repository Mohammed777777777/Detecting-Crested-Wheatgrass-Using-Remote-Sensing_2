{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7vrrP9IfO9W"
      },
      "outputs": [],
      "source": [
        "#Necessary packages\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn geemap -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "print(\"Work 1!!\")\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='usask-468318')\n",
        "print(\"Work 2!!\")"
      ],
      "metadata": {
        "id": "UVbFFYIafZuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your study area boundary\n",
        "SLPP = ee.FeatureCollection(\"projects/usask-468318/assets/SLPP\")\n",
        "# Plots\n",
        "plots = ee.FeatureCollection(\"projects/usask-468318/assets/Presence_Absence_Sites\")\n",
        "# Load smoothed NDVI time series (already created in GEE)\n",
        "ndviTimeSeries = ee.Image('users/Usask_Thesis/Smoothed_Sentinel_RGR_5_Day_24_19_iNaturalists').clip(SLPP)\n",
        "\n",
        "# Method 2: Get all band names and remove specific ones\n",
        "all_bands = ndviTimeSeries.bandNames()\n",
        "# Bands to remove (non-growing season)\n",
        "bands_to_remove = ee.List([\n",
        "    't00', 't01', 't02', 't03', 't04', 't05', 't06', 't07',\n",
        "    't08', 't09', 't10', 't11', 't12', 't13', 't14', 't15',\n",
        "    't16', 't17', 't61', 't62', 't63', 't64', 't65', 't66',\n",
        "    't67', 't68', 't69', 't70', 't71'\n",
        "])\n",
        "# Remove unwanted bands\n",
        "filtered_bands = all_bands.removeAll(bands_to_remove)\n",
        "\n",
        "# Select only filtered bands\n",
        "filtered_image = ndviTimeSeries.select(filtered_bands)\n",
        "# Print size\n",
        "print(f\"Plot data size: {plots.size().getInfo()}\")\n",
        "# Check NDVI bands\n",
        "band_names = ndviTimeSeries.bandNames().getInfo()\n",
        "print(f\"\\nNDVI bands: {len(band_names)} total\")\n",
        "print(f\"First 10 bands: {band_names[:10]}\")\n",
        "print(f\"Last 10 bands: {band_names[-10:]}\")\n"
      ],
      "metadata": {
        "id": "608fC2E1fnjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geemap\n",
        "\n",
        "# Create interactive map\n",
        "Map = geemap.Map()\n",
        "\n",
        "# Center on your study area\n",
        "Map.centerObject(SLPP, 12)\n",
        "\n",
        "# Add boundary and plots\n",
        "Map.addLayer(SLPP, {'color': 'yellow'}, 'SLPP Boundary')\n",
        "Map.addLayer(plots, {'color': 'red'}, 'Plot Data')\n",
        "\n",
        "# Get all band names from FILTERED image\n",
        "band_list = filtered_bands.getInfo()\n",
        "\n",
        "print(f\"Adding {len(band_list)} NDVI bands to map...\")\n",
        "\n",
        "# Add each NDVI band (all unchecked initially)\n",
        "for i, band_name in enumerate(band_list):\n",
        "    Map.addLayer(\n",
        "        filtered_image.select(band_name),\n",
        "        {\n",
        "            'min': 0,\n",
        "            'max': 1,\n",
        "            'palette': ['red', 'yellow', 'green']\n",
        "        },\n",
        "        f'NDVI {band_name}',\n",
        "        False  # False = unchecked initially\n",
        "    )\n",
        "\n",
        "    # Print progress every 10 bands\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"  Added {i + 1}/{len(band_list)} bands...\")\n",
        "\n",
        "print(f\"âœ… All {len(band_list)} NDVI bands added to map!\")\n",
        "print(\"Toggle layers on/off in the Layers panel â†’\")\n",
        "\n",
        "# Display the map\n",
        "Map\n"
      ],
      "metadata": {
        "id": "c7JzPDAUffhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add class labels (0 = Presence, 1 = Absence)\n",
        "def add_class_label(feature):\n",
        "    Type = feature.get('Type')\n",
        "    class_label = ee.Algorithms.If(ee.String(Type).equals('Presence'), 0, 1)\n",
        "    return feature.set('class', class_label)\n",
        "\n",
        "trainingData = plots.map(add_class_label)\n",
        "\n",
        "# Or display by species with different colors\n",
        "PPoints = trainingData.filter(ee.Filter.eq('Type', 'Presence'))\n",
        "APoints = trainingData.filter(ee.Filter.eq('Type', 'Absence'))\n",
        "\n",
        "# Print sizes\n",
        "print(PPoints.size().getInfo(), \"Presence POINT\")\n",
        "print(APoints.size().getInfo(), \"Absence POINT\")"
      ],
      "metadata": {
        "id": "bxzq5wl1g4DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CREATE 20m Ã— 20m SQUARE BUFFERS AND SAMPLE NDVI\n",
        "# ========================================\n",
        "\n",
        "# Step 1: Create function to convert points to 20m Ã— 20m squares\n",
        "def create_square_buffer(feature):\n",
        "    \"\"\"\n",
        "    Creates a 20m Ã— 20m square buffer around a point\n",
        "    (10m in each direction from center)\n",
        "    \"\"\"\n",
        "    # Get the point geometry\n",
        "    point = feature.geometry()\n",
        "\n",
        "    # Create a 20m Ã— 20m square (10m radius)\n",
        "    # Using buffer creates a circle, then we'll use bounds() to make it square\n",
        "    square = point.buffer(10).bounds()\n",
        "\n",
        "    # Alternative: More precise square using coordinates\n",
        "    # Get point coordinates\n",
        "    coords = point.coordinates()\n",
        "    lon = ee.Number(coords.get(0))\n",
        "    lat = ee.Number(coords.get(1))\n",
        "\n",
        "    # Calculate corners (approximately 10m in degrees)\n",
        "    # 10m â‰ˆ 0.00009 degrees latitude\n",
        "    # 10m longitude varies by latitude, but ~0.00012 at 52Â°N\n",
        "    offset_lat = 0.00009  # 10m in latitude\n",
        "    offset_lon = 0.00012  # 10m in longitude (approximate for Saskatchewan)\n",
        "\n",
        "    # Create square polygon\n",
        "    square = ee.Geometry.Rectangle([\n",
        "        lon.subtract(offset_lon), lat.subtract(offset_lat),  # SW corner\n",
        "        lon.add(offset_lon), lat.add(offset_lat)             # NE corner\n",
        "    ])\n",
        "\n",
        "    # Return feature with square geometry\n",
        "    return feature.setGeometry(square)\n",
        "\n",
        "# Step 2: Apply buffer to all training points\n",
        "print(\"Creating 20m Ã— 20m square buffers around each point...\")\n",
        "square_plots = trainingData.map(create_square_buffer)\n",
        "\n",
        "# Check how many square plots you have\n",
        "total_squares = square_plots.size().getInfo()\n",
        "print(f\"âœ… Total square plots created: {total_squares}\")\n",
        "\n",
        "# Verify the buffer size\n",
        "first_square = square_plots.first()\n",
        "area = first_square.geometry().area()\n",
        "print(f\"Buffer area: {area.getInfo():.0f} mÂ² (should be ~400 mÂ² for 20Ã—20m)\")\n",
        "\n",
        "\n",
        "trainingDataWithNDVI = filtered_image.reduceRegions(\n",
        "    collection=square_plots,\n",
        "    reducer=ee.Reducer.mean(),  # Average all pixels in each square\n",
        "    scale=10                     # Use 10m pixels (Sentinel-2 native resolution)\n",
        ")\n",
        "\n",
        "# Step 4: Verify results\n",
        "print(f\"\\nâœ… Sampled {trainingDataWithNDVI.size().getInfo()} plots\")\n",
        "\n",
        "# Check total samples\n",
        "total_samples = trainingDataWithNDVI.size().getInfo()\n",
        "print(f\"âœ… Total samples with NDVI: {total_samples}\")\n",
        "\n",
        "# Check by class/species\n",
        "P_samples = trainingDataWithNDVI.filter(ee.Filter.eq('Type', 'Presence')).size().getInfo()\n",
        "A_samples = trainingDataWithNDVI.filter(ee.Filter.eq('Type', 'Absence')).size().getInfo()\n",
        "\n",
        "print(f\"  Presence samples: {P_samples}\")\n",
        "print(f\"  Absence samples: {A_samples}\")\n",
        "\n",
        "\n",
        "# Check one sample\n",
        "sample = trainingDataWithNDVI.first().getInfo()['properties']\n",
        "\n",
        "ndvi_keys = [k for k in sample.keys() if k.startswith('t')]\n",
        "print(f\"  NDVI bands: {len(ndvi_keys)} total\")\n",
        "print(f\"  First 5 NDVI values: {[sample[k] for k in sorted(ndvi_keys)[:5]]}\")\n"
      ],
      "metadata": {
        "id": "-z_4S-R4l_Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "def ee_to_pandas(fc, limit=None):\n",
        "    \"\"\"Convert Earth Engine FeatureCollection to pandas DataFrame\"\"\"\n",
        "    if limit:\n",
        "        fc = fc.limit(limit)\n",
        "\n",
        "    features = fc.getInfo()['features']\n",
        "    data = [f['properties'] for f in features]\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# **DEFINE YOUR DOY MAPPING HERE**\n",
        "START_DAY = 2        # First band represents day 2\n",
        "DAY_INTERVAL = 5     # Each subsequent band is 5 days later\n",
        "\n",
        "# Remove site \"N29\" from the dataset\n",
        "trainingDataWithNDVI = trainingDataWithNDVI.filter(\n",
        "    ee.Filter.neq('Site', 'N29')\n",
        ")\n",
        "\n",
        "# Check total samples\n",
        "total_samples = trainingDataWithNDVI.size().getInfo()\n",
        "print(f\"âœ… Total samples available: {total_samples}\")\n",
        "\n",
        "P_samples = trainingDataWithNDVI.filter(ee.Filter.eq('Type', 'Presence')).size().getInfo()\n",
        "A_samples = trainingDataWithNDVI.filter(ee.Filter.eq('Type', 'Absence')).size().getInfo()\n",
        "\n",
        "print(f\"  Presence samples: {P_samples}\")\n",
        "print(f\"  Absence samples: {A_samples}\\n\")\n",
        "\n",
        "# Download ALL data\n",
        "df = ee_to_pandas(trainingDataWithNDVI)\n",
        "\n",
        "print(f\"âœ… Downloaded {len(df)} samples with {len(df.columns)} columns\\n\")\n",
        "\n",
        "# **Identify ALL NDVI band columns**\n",
        "ndvi_cols = [col for col in df.columns if col.startswith('t') and len(col) == 3 and col[1:].isdigit()]\n",
        "ndvi_cols_sorted = sorted(ndvi_cols)  # Sort to keep bands in order\n",
        "\n",
        "print(f\"ðŸ“Š Found {len(ndvi_cols_sorted)} NDVI band columns\")\n",
        "print(f\"   First 5 bands: {ndvi_cols_sorted[:5]}\")\n",
        "print(f\"   Last 5 bands: {ndvi_cols_sorted[-5:]}\\n\")\n",
        "\n",
        "# **RESHAPE DATA FROM WIDE TO LONG FORMAT**\n",
        "\n",
        "# Create a list to store reshaped rows\n",
        "long_format_data = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    site = row['Site']\n",
        "    type_val = row['Type']\n",
        "\n",
        "    # For each band, create a new row\n",
        "    for band_name in ndvi_cols_sorted:\n",
        "        # Extract band number and calculate DOY\n",
        "        band_num = int(band_name[1:])  # Remove 't' and convert to int\n",
        "        doy = (band_num * DAY_INTERVAL) + START_DAY\n",
        "        ndvi_value = row[band_name]\n",
        "\n",
        "        long_format_data.append({\n",
        "            'Site': site,\n",
        "            'Type': type_val,\n",
        "            'Band': band_name,\n",
        "            'DOY': doy,\n",
        "            'NDVI': ndvi_value\n",
        "        })\n",
        "\n",
        "# Create new DataFrame in long format\n",
        "df_long = pd.DataFrame(long_format_data)\n",
        "\n",
        "print(f\"âœ… Reshaped data: {len(df_long)} rows (from {len(df)} samples Ã— {len(ndvi_cols_sorted)} bands)\\n\")\n",
        "\n",
        "# Set pandas display options\n",
        "pd.set_option('display.max_rows', 20)  # Show first/last 10 rows\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(\"\\nLast 15 rows:\")\n",
        "display(df_long)\n",
        "\n",
        "# Save and download\n",
        "df_long.to_csv('Sentinel-All-Bands-Long-Format.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('Sentinel-All-Bands-Long-Format.csv')\n",
        "\n",
        "print(f\"\\nâœ… Saved long format data with {len(df_long)} rows and columns: {df_long.columns.tolist()}\")"
      ],
      "metadata": {
        "id": "4AwoCSP-mtvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# GUARANTEED 80/20 STRATIFIED SPLIT\n",
        "# ========================================\n",
        "\n",
        "def stratified_split_exact(data):\n",
        "    \"\"\"\n",
        "    Ensures EXACT 80/20 split while maintaining class proportions\n",
        "    \"\"\"\n",
        "    # Separate classes\n",
        "    cw_data = data.filter(ee.Filter.eq('class', 0))\n",
        "    ng_data = data.filter(ee.Filter.eq('class', 1))\n",
        "\n",
        "    # Get counts\n",
        "    cw_total = cw_data.size().getInfo()\n",
        "    ng_total = ng_data.size().getInfo()\n",
        "    total = cw_total + ng_total\n",
        "\n",
        "    # Calculate exact split for each class\n",
        "    cw_train_n = int(cw_total * 0.8)\n",
        "    cw_test_n = cw_total - cw_train_n\n",
        "\n",
        "    ng_train_n = int(ng_total * 0.8)\n",
        "    ng_test_n = ng_total - ng_train_n\n",
        "\n",
        "    print(f\"Target split:\")\n",
        "    print(f\"  Presence: {cw_train_n} train, {cw_test_n} test (from {cw_total} total)\")\n",
        "    print(f\"  Absence: {ng_train_n} train, {ng_test_n} test (from {ng_total} total)\")\n",
        "    print(f\"  Total: {cw_train_n + ng_train_n} train ({(cw_train_n + ng_train_n)/total*100:.1f}%), \"\n",
        "          f\"{cw_test_n + ng_test_n} test ({(cw_test_n + ng_test_n)/total*100:.1f}%)\")\n",
        "\n",
        "    # Add random column for shuffling\n",
        "    cw_random = cw_data.randomColumn('random', 42)\n",
        "    ng_random = ng_data.randomColumn('random', 42)\n",
        "\n",
        "    # Sort by random column to shuffle\n",
        "    cw_sorted = cw_random.sort('random')\n",
        "    ng_sorted = ng_random.sort('random')\n",
        "\n",
        "    # Take exact number for training (first 80% after shuffle)\n",
        "    cw_train = cw_sorted.limit(cw_train_n)\n",
        "    ng_train = ng_sorted.limit(ng_train_n)\n",
        "\n",
        "    # Take remaining for testing (skip first 80%, take rest)\n",
        "    cw_test = cw_sorted.toList(cw_total).slice(cw_train_n)\n",
        "    ng_test = ng_sorted.toList(ng_total).slice(ng_train_n)\n",
        "\n",
        "    # Convert lists back to FeatureCollections\n",
        "    cw_test_fc = ee.FeatureCollection(cw_test)\n",
        "    ng_test_fc = ee.FeatureCollection(ng_test)\n",
        "\n",
        "    # Merge\n",
        "    train = cw_train.merge(ng_train)\n",
        "    test = cw_test_fc.merge(ng_test_fc)\n",
        "\n",
        "    return {'train': train, 'test': test}\n",
        "\n",
        "\n",
        "split_data = stratified_split_exact(trainingDataWithNDVI)\n",
        "\n",
        "# Verify\n",
        "train_total = split_data['train'].size().getInfo()\n",
        "test_total = split_data['test'].size().getInfo()\n",
        "total = train_total + test_total\n",
        "\n",
        "train_cw = split_data['train'].filter(ee.Filter.eq('class', 0)).size().getInfo()\n",
        "train_ng = split_data['train'].filter(ee.Filter.eq('class', 1)).size().getInfo()\n",
        "test_cw = split_data['test'].filter(ee.Filter.eq('class', 0)).size().getInfo()\n",
        "test_ng = split_data['test'].filter(ee.Filter.eq('class', 1)).size().getInfo()\n",
        "\n",
        "print(f\"\\nActual split:\")\n",
        "print(f\"  Training: {train_total} samples ({train_total/total*100:.1f}%)\")\n",
        "print(f\"    - Presence: {train_cw}\")\n",
        "print(f\"    - Absence: {train_ng}\")\n",
        "print(f\"  Testing: {test_total} samples ({test_total/total*100:.1f}%)\")\n",
        "print(f\"    - Presence: {test_cw}\")\n",
        "print(f\"    - Absence: {test_ng}\")\n",
        "\n",
        "# Check if it's 80/20\n",
        "train_pct = train_total / total * 100\n",
        "if abs(train_pct - 80) < 1:\n",
        "    print(f\"\\nâœ… Split is exactly 80/20!\")\n",
        "else:\n",
        "    print(f\"\\nâš ï¸  Split is {train_pct:.1f}% / {100-train_pct:.1f}%\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "KySmpdpfpx4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# HYPERPARAMETER TUNING - LOOCV WITH REDUCED RANGES\n",
        "# ========================================\n",
        "\n",
        "training_set = split_data['train']\n",
        "temporal_bands = filtered_image.bandNames()\n",
        "n_samples = training_set.size().getInfo()\n",
        "\n",
        "print(f\"\\nTraining samples: {n_samples}\")\n",
        "\n",
        "# Step 1: Prepare data with IDs\n",
        "print(\"\\nPreparing data for LOOCV...\")\n",
        "training_list = training_set.toList(n_samples)\n",
        "\n",
        "def add_id(i):\n",
        "    feature = ee.Feature(training_list.get(i))\n",
        "    return feature.set('loocv_id', i)\n",
        "\n",
        "features_with_id = ee.List.sequence(0, n_samples - 1).map(add_id)\n",
        "training_with_id = ee.FeatureCollection(features_with_id)\n",
        "print(f\"âœ… Added sequential IDs (0 to {n_samples - 1})\")\n",
        "\n",
        "# ========================================\n",
        "# DEFINE HYPERPARAMETER RANGES (WITH SQRT AND LOG2)\n",
        "# ========================================\n",
        "\n",
        "import itertools\n",
        "import math\n",
        "\n",
        "# Calculate number of features\n",
        "n_features = temporal_bands.size().getInfo()\n",
        "print(f\"\\nTotal NDVI features: {n_features}\")\n",
        "\n",
        "# Calculate sqrt and log2 values\n",
        "vars_sqrt = int(math.sqrt(n_features))\n",
        "vars_log2 = int(math.log2(n_features))\n",
        "\n",
        "print(f\"  sqrt({n_features}) = {vars_sqrt}\")\n",
        "print(f\"  log2({n_features}) = {vars_log2}\")\n",
        "\n",
        "# FAST VERSION with automatic feature selection\n",
        "trees_range = [100, 200, 400]                    # 3 values\n",
        "vars_range = ['sqrt', 'log2']                # sqrt, log2, or fixed value\n",
        "minLeaf_range = [1, 5, 10]                       # 3 values\n",
        "bag_fraction_list = [0.7, 0.9]                   # 2 values\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HYPERPARAMETER RANGES (OPTIMIZED FOR SPEED)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"numberOfTrees: {trees_range}\")\n",
        "print(f\"variablesPerSplit: {vars_range}\")\n",
        "print(f\"  - 'sqrt' will use {vars_sqrt} features\")\n",
        "print(f\"  - 'log2' will use {vars_log2} features\")\n",
        "print(f\"  - 10 will use 10 features\")\n",
        "print(f\"minLeafPopulation: {minLeaf_range}\")\n",
        "print(f\"bagFraction: {bag_fraction_list}\")\n",
        "\n",
        "# Generate all combinations\n",
        "param_combinations = list(itertools.product(trees_range, vars_range, minLeaf_range, bag_fraction_list))\n",
        "\n",
        "print(f\"\\nðŸ“Š Total combinations to test: {len(param_combinations)}\")\n",
        "print(f\"   3 Ã— 3 Ã— 3 Ã— 2 = {3*3*3*2} configurations\")\n",
        "print(f\"   Each config trains {n_samples} models\")\n",
        "print(f\"   Total model trainings: {len(param_combinations) * n_samples}\")\n",
        "print(f\"â±ï¸  Estimated time: ~{len(param_combinations) * n_samples * 3 / 60:.0f} minutes ({len(param_combinations) * n_samples * 3 / 3600:.1f} hours)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Convert to list of dictionaries\n",
        "param_grid = []\n",
        "for idx, (trees, vars_val, minLeaf, bag_frac) in enumerate(param_combinations, 1):\n",
        "    # Convert sqrt/log2 to actual numbers\n",
        "    if vars_val == 'sqrt':\n",
        "        actual_vars = vars_sqrt\n",
        "        vars_display = f\"sqrt({vars_sqrt})\"\n",
        "    elif vars_val == 'log2':\n",
        "        actual_vars = vars_log2\n",
        "        vars_display = f\"log2({vars_log2})\"\n",
        "    else:\n",
        "        actual_vars = vars_val\n",
        "        vars_display = str(vars_val)\n",
        "\n",
        "    param_grid.append({\n",
        "        'name': f'Config_{idx}',\n",
        "        'trees': trees,\n",
        "        'vars': actual_vars,           # Actual numeric value for GEE\n",
        "        'vars_type': vars_val,          # Original type (sqrt/log2/number)\n",
        "        'vars_display': vars_display,   # For display\n",
        "        'minLeaf': minLeaf,\n",
        "        'bagFraction': bag_frac\n",
        "    })\n",
        "\n",
        "print(f\"\\nâœ… Generated {len(param_grid)} configurations\")\n",
        "\n",
        "# Show all configurations\n",
        "print(\"\\nAll configurations to test:\")\n",
        "for i in range(len(param_grid)):\n",
        "    p = param_grid[i]\n",
        "    print(f\"  {p['name']}: trees={p['trees']}, vars={p['vars_display']}, minLeaf={p['minLeaf']}, bagFrac={p['bagFraction']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# ========================================\n",
        "# LOOCV FUNCTION (DEFINED BEFORE THE LOOP)\n",
        "# ========================================\n",
        "\n",
        "def leave_one_out_cv(params, data_with_id, bands, n):\n",
        "    \"\"\"Perform leave-one-out cross-validation\"\"\"\n",
        "    correct = 0\n",
        "    predictions_list = []\n",
        "\n",
        "    print(f\"  Running LOOCV ({n} iterations)...\")\n",
        "\n",
        "    for i in range(n):\n",
        "        # Leave one out\n",
        "        test_sample = data_with_id.filter(ee.Filter.eq('loocv_id', i))\n",
        "        train_samples = data_with_id.filter(ee.Filter.neq('loocv_id', i))\n",
        "\n",
        "        # Verify we have data\n",
        "        test_size = test_sample.size().getInfo()\n",
        "        train_size = train_samples.size().getInfo()\n",
        "\n",
        "        if test_size == 0:\n",
        "            continue\n",
        "        if train_size == 0:\n",
        "            continue\n",
        "\n",
        "        # Train with bag fraction parameter\n",
        "        classifier = ee.Classifier.smileRandomForest(\n",
        "            numberOfTrees=params['trees'],\n",
        "            variablesPerSplit=params['vars'],  # This is now the actual numeric value\n",
        "            minLeafPopulation=params['minLeaf'],\n",
        "            bagFraction=params['bagFraction'],\n",
        "            seed=42\n",
        "        )\n",
        "\n",
        "        trained = classifier.train(\n",
        "            features=train_samples,\n",
        "            classProperty='class',\n",
        "            inputProperties=bands\n",
        "        )\n",
        "\n",
        "        # Test on single sample\n",
        "        prediction = test_sample.classify(trained)\n",
        "\n",
        "        # Get actual and predicted classes\n",
        "        test_feature = test_sample.first().getInfo()\n",
        "        if test_feature is None:\n",
        "            continue\n",
        "\n",
        "        pred_feature = prediction.first().getInfo()\n",
        "        if pred_feature is None:\n",
        "            continue\n",
        "\n",
        "        actual = test_feature['properties'].get('class')\n",
        "        predicted = pred_feature['properties'].get('classification')\n",
        "\n",
        "        if actual == predicted:\n",
        "            correct += 1\n",
        "\n",
        "        predictions_list.append({\n",
        "            'id': i,\n",
        "            'actual': actual,\n",
        "            'predicted': predicted,\n",
        "            'correct': actual == predicted\n",
        "        })\n",
        "\n",
        "        # Progress updates every 20 iterations\n",
        "        if (i + 1) % 20 == 0:\n",
        "            accuracy_so_far = correct / (i + 1) * 100\n",
        "            print(f\"    Progress: {i+1}/{n} ({correct}/{i+1} correct, {accuracy_so_far:.1f}%)\")\n",
        "\n",
        "    total = len(predictions_list)\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'correct': correct,\n",
        "        'total': total,\n",
        "        'predictions': predictions_list\n",
        "    }\n",
        "\n",
        "# ========================================\n",
        "# RUN LOOCV FOR EACH CONFIG\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = []\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "for idx, params in enumerate(param_grid, 1):\n",
        "    config_start = time.time()\n",
        "\n",
        "    print(f\"\\n[{idx}/{len(param_grid)}] {params['name']}: trees={params['trees']}, vars={params['vars_display']}, minLeaf={params['minLeaf']}, bagFrac={params['bagFraction']}\")\n",
        "\n",
        "    loocv_result = leave_one_out_cv(params, training_with_id, temporal_bands, n_samples)\n",
        "\n",
        "    result = {\n",
        "        'config': params['name'],\n",
        "        'trees': params['trees'],\n",
        "        'vars': params['vars'],            # Numeric value\n",
        "        'vars_type': params['vars_type'],  # sqrt/log2/number\n",
        "        'vars_display': params['vars_display'],  # For readability\n",
        "        'minLeaf': params['minLeaf'],\n",
        "        'bagFraction': params['bagFraction'],\n",
        "        'accuracy': loocv_result['accuracy'],\n",
        "        'correct': loocv_result['correct'],\n",
        "        'total': loocv_result['total']\n",
        "    }\n",
        "    results.append(result)\n",
        "\n",
        "    config_time = time.time() - config_start\n",
        "    elapsed_total = time.time() - start_time\n",
        "    remaining_configs = len(param_grid) - idx\n",
        "    estimated_remaining = (elapsed_total / idx) * remaining_configs\n",
        "\n",
        "    print(f\"  âœ… LOOCV Accuracy: {loocv_result['accuracy']*100:.2f}% ({loocv_result['correct']}/{loocv_result['total']})\")\n",
        "    print(f\"  â±ï¸  Config time: {config_time/60:.1f} min | Elapsed: {elapsed_total/60:.1f} min | ETA: {estimated_remaining/60:.1f} min\")\n",
        "\n",
        "    # Show current best so far\n",
        "    current_best = max(results, key=lambda x: x['accuracy'])\n",
        "    print(f\"  ðŸ† Best so far: {current_best['accuracy']*100:.2f}% (trees={current_best['trees']}, vars={current_best['vars_display']}, minLeaf={current_best['minLeaf']}, bagFrac={current_best['bagFraction']})\")\n",
        "\n",
        "# ========================================\n",
        "# FINAL RESULTS\n",
        "# ========================================\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HYPERPARAMETER TUNING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total time: {total_time/3600:.2f} hours ({total_time/60:.1f} minutes)\")\n",
        "print(f\"Tested {len(param_grid)} configurations\")\n",
        "print(f\"Speed improvement: Tested 54 configs instead of 375 (7x faster!)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Sort results\n",
        "results_sorted = sorted(results, key=lambda x: x['accuracy'], reverse=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ALL CONFIGURATIONS (RANKED BY ACCURACY)\")\n",
        "print(\"=\"*60)\n",
        "for i, r in enumerate(results_sorted, 1):\n",
        "    print(f\"{i}. {r['config']}: {r['accuracy']*100:.2f}% ({r['correct']}/{r['total']})\")\n",
        "    print(f\"   trees={r['trees']}, vars={r['vars_display']}, minLeaf={r['minLeaf']}, bagFrac={r['bagFraction']}\")\n",
        "\n",
        "# Best configuration\n",
        "best = results_sorted[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ† BEST HYPERPARAMETERS (LOOCV)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Configuration: {best['config']}\")\n",
        "print(f\"  numberOfTrees: {best['trees']}\")\n",
        "print(f\"  variablesPerSplit: {best['vars']} ({best['vars_type']})\")\n",
        "print(f\"  minLeafPopulation: {best['minLeaf']}\")\n",
        "print(f\"  bagFraction: {best['bagFraction']}\")\n",
        "print(f\"  LOOCV Accuracy: {best['accuracy']*100:.2f}%\")\n",
        "print(f\"  Correct predictions: {best['correct']}/{best['total']}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_params = {\n",
        "    'numberOfTrees': best['trees'],\n",
        "    'variablesPerSplit': best['vars'],\n",
        "    'minLeafPopulation': best['minLeaf'],\n",
        "    'bagFraction': best['bagFraction']\n",
        "}\n",
        "\n",
        "print(\"\\nâœ… Best parameters saved in 'best_params'\")\n",
        "\n",
        "# ========================================\n",
        "# SAVE RESULTS TO CSV\n",
        "# ========================================\n",
        "\n",
        "print(\"\\nðŸ“Š Saving all results to CSV...\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('accuracy', ascending=False)\n",
        "results_df.to_csv('loocv_hyperparameter_results_fast.csv', index=False)\n",
        "\n",
        "print(\"âœ… Results saved to 'loocv_hyperparameter_results_fast.csv'\")\n",
        "print(\"\\nYou can download this file to analyze results\")\n",
        "\n",
        "# ========================================\n",
        "# SUMMARY STATISTICS\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "accuracies = [r['accuracy'] for r in results]\n",
        "print(f\"Average accuracy across all configs: {sum(accuracies)/len(accuracies)*100:.2f}%\")\n",
        "print(f\"Best accuracy: {max(accuracies)*100:.2f}%\")\n",
        "print(f\"Worst accuracy: {min(accuracies)*100:.2f}%\")\n",
        "print(f\"Range: {(max(accuracies)-min(accuracies))*100:.2f}%\")\n",
        "\n",
        "# Analysis by vars_type\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PERFORMANCE BY VARIABLE SELECTION METHOD\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for vars_type in ['sqrt', 'log2', 10]:\n",
        "    type_results = [r for r in results if r['vars_type'] == vars_type]\n",
        "    if type_results:\n",
        "        type_accuracies = [r['accuracy'] for r in type_results]\n",
        "        avg_acc = sum(type_accuracies) / len(type_accuracies) * 100\n",
        "        if vars_type == 'sqrt':\n",
        "            print(f\"sqrt ({vars_sqrt} features): Average accuracy = {avg_acc:.2f}%\")\n",
        "        elif vars_type == 'log2':\n",
        "            print(f\"log2 ({vars_log2} features): Average accuracy = {avg_acc:.2f}%\")\n",
        "        else:\n",
        "            print(f\"Fixed (10 features): Average accuracy = {avg_acc:.2f}%\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "k_cttZNHqkXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #========================================\n",
        "# STEP 1: RFE ON TRAINING SET ONLY\n",
        "# (To avoid data leakage - don't use test set!)\n",
        "# ========================================\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Get training set\n",
        "training_set = split_data['train']\n",
        "n_train_samples = training_set.size().getInfo()\n",
        "\n",
        "# Get all feature names\n",
        "all_features = filtered_bands.getInfo()\n",
        "n_features_total = len(all_features)\n",
        "\n",
        "# ========================================\n",
        "# RFE CONFIGURATION\n",
        "# ========================================\n",
        "\n",
        "STOPPING_STRATEGY = \"absolute_drop\"\n",
        "absolute_drop_threshold = 2.0  # Stop if accuracy drops >2%\n",
        "elimination_step = 1  # Remove 1 feature per iteration\n",
        "min_features = 5  # Safety limit\n",
        "max_iterations = 20  # Safety limit\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# RFE HELPER FUNCTIONS (TRAINING SET ONLY)\n",
        "# ========================================\n",
        "def rfe_train_test_iteration(features_list, train_data, hyperparams):\n",
        "    \"\"\"\n",
        "    Perform internal 5-fold CV on TRAINING SET ONLY\n",
        "    Returns average accuracy across folds\n",
        "    \"\"\"\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "    # We'll do 5-fold CV within training set for speed\n",
        "    n_folds = 10\n",
        "\n",
        "    # Create stratified folds within training set\n",
        "    train_cw = train_data.filter(ee.Filter.eq('class', 0))\n",
        "    train_ng = train_data.filter(ee.Filter.eq('class', 1))\n",
        "\n",
        "    cw_total = train_cw.size().getInfo()\n",
        "    ng_total = train_ng.size().getInfo()\n",
        "\n",
        "    # Add random column and sort\n",
        "    cw_random = train_cw.randomColumn('rfe_fold', 42)\n",
        "    ng_random = train_ng.randomColumn('rfe_fold', 42)\n",
        "    cw_sorted = cw_random.sort('rfe_fold')\n",
        "    ng_sorted = ng_random.sort('rfe_fold')\n",
        "\n",
        "    # Convert to lists\n",
        "    cw_list = cw_sorted.toList(cw_total)\n",
        "    ng_list = ng_sorted.toList(ng_total)\n",
        "\n",
        "    # Calculate fold sizes\n",
        "    cw_fold_size = int(cw_total / n_folds)\n",
        "    ng_fold_size = int(ng_total / n_folds)\n",
        "\n",
        "    fold_accuracies = []\n",
        "    bands_to_use = ee.List(features_list)\n",
        "\n",
        "    for fold_idx in range(n_folds):\n",
        "        # Create test fold\n",
        "        cw_test_start = fold_idx * cw_fold_size\n",
        "        cw_test_end = (fold_idx + 1) * cw_fold_size if fold_idx < n_folds - 1 else cw_total\n",
        "\n",
        "        ng_test_start = fold_idx * ng_fold_size\n",
        "        ng_test_end = (fold_idx + 1) * ng_fold_size if fold_idx < n_folds - 1 else ng_total\n",
        "\n",
        "        cw_test_fold = ee.FeatureCollection(cw_list.slice(cw_test_start, cw_test_end))\n",
        "        ng_test_fold = ee.FeatureCollection(ng_list.slice(ng_test_start, ng_test_end))\n",
        "\n",
        "        test_fold = cw_test_fold.merge(ng_test_fold)\n",
        "\n",
        "        # Create train fold (all except test)\n",
        "        cw_train_part1 = ee.FeatureCollection(cw_list.slice(0, cw_test_start))\n",
        "        cw_train_part2 = ee.FeatureCollection(cw_list.slice(cw_test_end, cw_total))\n",
        "\n",
        "        ng_train_part1 = ee.FeatureCollection(ng_list.slice(0, ng_test_start))\n",
        "        ng_train_part2 = ee.FeatureCollection(ng_list.slice(ng_test_end, ng_total))\n",
        "\n",
        "        train_fold = cw_train_part1.merge(cw_train_part2).merge(ng_train_part1).merge(ng_train_part2)\n",
        "\n",
        "        # Train classifier\n",
        "        classifier = ee.Classifier.smileRandomForest(\n",
        "            numberOfTrees=hyperparams['numberOfTrees'],\n",
        "            variablesPerSplit=hyperparams['variablesPerSplit'],\n",
        "            minLeafPopulation=hyperparams['minLeafPopulation'],\n",
        "            bagFraction=hyperparams['bagFraction'],\n",
        "            seed=42\n",
        "        )\n",
        "\n",
        "        trained = classifier.train(\n",
        "            features=train_fold,\n",
        "            classProperty='class',\n",
        "            inputProperties=bands_to_use\n",
        "        )\n",
        "\n",
        "        # Predict\n",
        "        predictions = test_fold.classify(trained)\n",
        "\n",
        "        # Get accuracy\n",
        "        error_matrix = predictions.errorMatrix('class', 'classification')\n",
        "        accuracy = error_matrix.accuracy().getInfo()\n",
        "\n",
        "        fold_accuracies.append(accuracy)\n",
        "\n",
        "    return {\n",
        "        'accuracy_mean': np.mean(fold_accuracies),\n",
        "        'accuracy_std': np.std(fold_accuracies)\n",
        "    }\n",
        "\n",
        "def get_feature_importance_train(features_list, training_data, hyperparams):\n",
        "    \"\"\"\n",
        "    Train on training set only and get feature importance\n",
        "    \"\"\"\n",
        "    bands_to_use = ee.List(features_list)\n",
        "\n",
        "    classifier = ee.Classifier.smileRandomForest(\n",
        "        numberOfTrees=hyperparams['numberOfTrees'],\n",
        "        variablesPerSplit=hyperparams['variablesPerSplit'],\n",
        "        minLeafPopulation=hyperparams['minLeafPopulation'],\n",
        "        bagFraction=hyperparams['bagFraction'],\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    trained = classifier.train(\n",
        "        features=training_data,\n",
        "        classProperty='class',\n",
        "        inputProperties=bands_to_use\n",
        "    )\n",
        "\n",
        "    explanation = trained.explain().getInfo()\n",
        "    importance_dict = explanation.get('importance', {})\n",
        "\n",
        "    return importance_dict\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# RFE MAIN LOOP (ON TRAINING SET ONLY)\n",
        "# ========================================\n",
        "\n",
        "rfe_results = []\n",
        "current_features = all_features.copy()\n",
        "iteration = 0\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"STARTING RFE ON TRAINING SET...\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "while True:\n",
        "    iteration += 1\n",
        "    iter_start = time.time()\n",
        "\n",
        "    n_current = len(current_features)\n",
        "\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"RFE ITERATION {iteration}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Current features: {n_current}\")\n",
        "\n",
        "    # Evaluate with 5-fold CV on training set\n",
        "    print(f\"\\n  Running 5-fold CV on training set...\")\n",
        "    cv_results = rfe_train_test_iteration(current_features, training_set, best_params)\n",
        "\n",
        "    accuracy = cv_results['accuracy_mean']\n",
        "\n",
        "    # Calculate drops\n",
        "    if len(rfe_results) > 0:\n",
        "        baseline_accuracy = rfe_results[0]['accuracy_mean']\n",
        "        drop_from_baseline = (baseline_accuracy - accuracy) * 100\n",
        "    else:\n",
        "        baseline_accuracy = accuracy\n",
        "        drop_from_baseline = 0\n",
        "\n",
        "    print(f\"\\n  âœ… 5-Fold CV Results:\")\n",
        "    print(f\"     Accuracy: {accuracy*100:.2f}% (Â±{cv_results['accuracy_std']*100:.2f}%)\")\n",
        "\n",
        "    if len(rfe_results) > 0:\n",
        "        print(f\"     Drop from baseline: {drop_from_baseline:.2f} percentage points\")\n",
        "\n",
        "    # Store results\n",
        "    rfe_results.append({\n",
        "        'iteration': iteration,\n",
        "        'n_features': n_current,\n",
        "        'features': current_features.copy(),\n",
        "        'accuracy_mean': accuracy,\n",
        "        'accuracy_std': cv_results['accuracy_std'],\n",
        "        'drop_from_baseline': drop_from_baseline / 100\n",
        "    })\n",
        "\n",
        "    # Check stopping condition\n",
        "    should_stop = False\n",
        "\n",
        "    if len(rfe_results) > 1:\n",
        "        if drop_from_baseline > absolute_drop_threshold:\n",
        "            should_stop = True\n",
        "            print(f\"\\n  ðŸ›‘ STOPPING: Accuracy dropped by {drop_from_baseline:.2f}% (threshold: {absolute_drop_threshold}%)\")\n",
        "\n",
        "    if n_current <= min_features:\n",
        "        should_stop = True\n",
        "        print(f\"\\n  ðŸ›‘ STOPPING: Reached minimum features ({min_features})\")\n",
        "\n",
        "    if iteration >= max_iterations:\n",
        "        should_stop = True\n",
        "        print(f\"\\n  ðŸ›‘ STOPPING: Reached maximum iterations ({max_iterations})\")\n",
        "\n",
        "    if should_stop:\n",
        "        if len(rfe_results) > 1:\n",
        "            optimal_iter = rfe_results[-2]  # Previous iteration\n",
        "            print(f\"\\n  âœ… OPTIMAL: Iteration {optimal_iter['iteration']} with {optimal_iter['n_features']} features\")\n",
        "        else:\n",
        "            optimal_iter = rfe_results[-1]\n",
        "            print(f\"\\n  âœ… OPTIMAL: Keeping all {optimal_iter['n_features']} features\")\n",
        "        break\n",
        "\n",
        "    # Continue: Get feature importance\n",
        "    print(f\"\\n  âž¡ï¸  Extracting feature importance...\")\n",
        "    importance_dict = get_feature_importance_train(current_features, training_set, best_params)\n",
        "\n",
        "    # Sort by importance\n",
        "    sorted_features = sorted(importance_dict.items(), key=lambda x: x[1])\n",
        "\n",
        "    # Remove least important\n",
        "    n_to_remove = min(elimination_step, len(current_features) - min_features)\n",
        "    features_to_remove = [feat for feat, _ in sorted_features[:n_to_remove]]\n",
        "\n",
        "    print(f\"\\n  ðŸ—‘ï¸  Removing: {features_to_remove}\")\n",
        "    current_features = [f for f in current_features if f not in features_to_remove]\n",
        "\n",
        "    iter_time = time.time() - iter_start\n",
        "    print(f\"\\n  â±ï¸  Iteration time: {iter_time/60:.1f} min\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "# Find best iteration\n",
        "best_rfe = max(rfe_results, key=lambda x: x['accuracy_mean'])\n",
        "rfe_selected_features = best_rfe['features']\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ‰ RFE COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total time: {total_time/60:.1f} minutes\")\n",
        "print(f\"\\nðŸ† OPTIMAL FEATURES:\")\n",
        "print(f\"   Number: {best_rfe['n_features']}\")\n",
        "print(f\"   Features: {rfe_selected_features}\")\n",
        "print(f\"   Training CV Accuracy: {best_rfe['accuracy_mean']*100:.2f}% (Â±{best_rfe['accuracy_std']*100:.2f}%)\")\n",
        "\n",
        "# ========================================\n",
        "# VISUALIZE RFE RESULTS\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATING RFE VISUALIZATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert results to DataFrame for easier plotting\n",
        "rfe_df = pd.DataFrame([{\n",
        "    'iteration': r['iteration'],\n",
        "    'n_features': r['n_features'],\n",
        "    'accuracy_mean': r['accuracy_mean'] * 100,  # Convert to percentage\n",
        "    'accuracy_std': r['accuracy_std'] * 100,\n",
        "    'drop_from_baseline': r['drop_from_baseline'] * 100\n",
        "} for r in rfe_results])\n",
        "\n",
        "print(f\"\\nCreating {len(rfe_df)} iteration plots...\")\n",
        "\n",
        "# ========================================\n",
        "# FIGURE 1: COMPREHENSIVE RFE VISUALIZATION\n",
        "# ========================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Accuracy vs Number of Features (with error bars)\n",
        "ax1 = axes[0, 0]\n",
        "ax1.errorbar(rfe_df['n_features'], rfe_df['accuracy_mean'],\n",
        "             yerr=rfe_df['accuracy_std'],\n",
        "             marker='o', markersize=8, capsize=5, capthick=2,\n",
        "             linewidth=2.5, color='#2E86AB', label='CV Accuracy')\n",
        "\n",
        "# Mark optimal point\n",
        "best_idx = rfe_df['accuracy_mean'].idxmax()\n",
        "ax1.scatter(rfe_df.loc[best_idx, 'n_features'],\n",
        "           rfe_df.loc[best_idx, 'accuracy_mean'],\n",
        "           color='#A23B72', s=400, marker='*', zorder=5,\n",
        "           label=f'Optimal: {rfe_df.loc[best_idx, \"n_features\"]} features',\n",
        "           edgecolors='black', linewidths=2)\n",
        "\n",
        "# Mark stopping point\n",
        "ax1.scatter(rfe_df.iloc[-1]['n_features'],\n",
        "           rfe_df.iloc[-1]['accuracy_mean'],\n",
        "           color='red', s=300, marker='X', zorder=5,\n",
        "           label='Stopping Point',\n",
        "           edgecolors='black', linewidths=2)\n",
        "\n",
        "ax1.set_xlabel('Number of Features', fontsize=13, fontweight='bold')\n",
        "ax1.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
        "ax1.set_title('RFE: Accuracy vs Number of Features', fontsize=15, fontweight='bold')\n",
        "ax1.legend(fontsize=11, loc='best')\n",
        "ax1.grid(True, alpha=0.3, linestyle='--')\n",
        "ax1.invert_xaxis()  # More features on left, fewer on right\n",
        "\n",
        "# Add text annotation for optimal point\n",
        "ax1.annotate(f'{rfe_df.loc[best_idx, \"accuracy_mean\"]:.2f}%',\n",
        "            xy=(rfe_df.loc[best_idx, 'n_features'], rfe_df.loc[best_idx, 'accuracy_mean']),\n",
        "            xytext=(10, 10), textcoords='offset points',\n",
        "            fontsize=10, fontweight='bold',\n",
        "            bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),\n",
        "            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
        "\n",
        "# Plot 2: Accuracy Drop from Baseline\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(rfe_df['n_features'], rfe_df['drop_from_baseline'],\n",
        "         marker='o', markersize=8, linewidth=2.5, color='#F18F01')\n",
        "\n",
        "# Add threshold line\n",
        "ax2.axhline(y=absolute_drop_threshold, color='#C73E1D',\n",
        "           linestyle='--', linewidth=2.5,\n",
        "           label=f'Threshold ({absolute_drop_threshold}% drop)')\n",
        "\n",
        "# Fill acceptable zone\n",
        "ax2.fill_between(rfe_df['n_features'], 0, absolute_drop_threshold,\n",
        "                alpha=0.2, color='green', label='Acceptable Zone')\n",
        "\n",
        "# Fill unacceptable zone\n",
        "ax2.fill_between(rfe_df['n_features'], absolute_drop_threshold,\n",
        "                rfe_df['drop_from_baseline'].max() + 1,\n",
        "                alpha=0.2, color='red', label='Unacceptable Zone')\n",
        "\n",
        "ax2.set_xlabel('Number of Features', fontsize=13, fontweight='bold')\n",
        "ax2.set_ylabel('Accuracy Drop from Baseline (% points)', fontsize=13, fontweight='bold')\n",
        "ax2.set_title('Performance Degradation from Baseline', fontsize=15, fontweight='bold')\n",
        "ax2.legend(fontsize=11, loc='best')\n",
        "ax2.grid(True, alpha=0.3, linestyle='--')\n",
        "ax2.invert_xaxis()\n",
        "\n",
        "# Plot 3: Accuracy with Standard Deviation Bands\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(rfe_df['n_features'], rfe_df['accuracy_mean'],\n",
        "        marker='o', markersize=8, linewidth=2.5, color='#2E86AB', label='Mean Accuracy')\n",
        "\n",
        "# Add confidence bands (Â±1 std)\n",
        "ax3.fill_between(rfe_df['n_features'],\n",
        "                rfe_df['accuracy_mean'] - rfe_df['accuracy_std'],\n",
        "                rfe_df['accuracy_mean'] + rfe_df['accuracy_std'],\n",
        "                alpha=0.3, color='#2E86AB', label='Â±1 Std Dev')\n",
        "\n",
        "# Mark optimal\n",
        "ax3.scatter(rfe_df.loc[best_idx, 'n_features'],\n",
        "           rfe_df.loc[best_idx, 'accuracy_mean'],\n",
        "           color='#A23B72', s=400, marker='*', zorder=5,\n",
        "           edgecolors='black', linewidths=2)\n",
        "\n",
        "ax3.set_xlabel('Number of Features', fontsize=13, fontweight='bold')\n",
        "ax3.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
        "ax3.set_title('RFE: Accuracy with Uncertainty', fontsize=15, fontweight='bold')\n",
        "ax3.legend(fontsize=11, loc='best')\n",
        "ax3.grid(True, alpha=0.3, linestyle='--')\n",
        "ax3.invert_xaxis()\n",
        "\n",
        "# Plot 4: Iteration Progress\n",
        "ax4 = axes[1, 1]\n",
        "ax4.plot(rfe_df['iteration'], rfe_df['accuracy_mean'],\n",
        "        marker='o', markersize=8, linewidth=2.5, color='#6A994E')\n",
        "\n",
        "# Mark optimal iteration\n",
        "ax4.scatter(rfe_df.loc[best_idx, 'iteration'],\n",
        "           rfe_df.loc[best_idx, 'accuracy_mean'],\n",
        "           color='#A23B72', s=400, marker='*', zorder=5,\n",
        "           label=f'Optimal: Iteration {rfe_df.loc[best_idx, \"iteration\"]}',\n",
        "           edgecolors='black', linewidths=2)\n",
        "\n",
        "# Mark stopping iteration\n",
        "ax4.scatter(rfe_df.iloc[-1]['iteration'],\n",
        "           rfe_df.iloc[-1]['accuracy_mean'],\n",
        "           color='red', s=300, marker='X', zorder=5,\n",
        "           label='Stopped',\n",
        "           edgecolors='black', linewidths=2)\n",
        "\n",
        "ax4.set_xlabel('RFE Iteration', fontsize=13, fontweight='bold')\n",
        "ax4.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
        "ax4.set_title('RFE Progress Over Iterations', fontsize=15, fontweight='bold')\n",
        "ax4.legend(fontsize=11, loc='best')\n",
        "ax4.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('rfe_comprehensive_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"âœ… Saved: rfe_comprehensive_analysis.png\")\n",
        "\n",
        "# ========================================\n",
        "# FIGURE 2: SINGLE CLEAN PLOT FOR THESIS\n",
        "# ========================================\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Main accuracy line with error bars\n",
        "ax.errorbar(rfe_df['n_features'], rfe_df['accuracy_mean'],\n",
        "           yerr=rfe_df['accuracy_std'],\n",
        "           marker='o', markersize=10, capsize=6, capthick=2.5,\n",
        "           linewidth=3, color='#2E86AB',\n",
        "           label='Cross-Validation Accuracy', zorder=2)\n",
        "\n",
        "# Mark optimal point (larger and more prominent)\n",
        "ax.scatter(rfe_df.loc[best_idx, 'n_features'],\n",
        "          rfe_df.loc[best_idx, 'accuracy_mean'],\n",
        "          color='gold', s=600, marker='*', zorder=5,\n",
        "          label=f'Optimal: {rfe_df.loc[best_idx, \"n_features\"]} features ({rfe_df.loc[best_idx, \"accuracy_mean\"]:.2f}%)',\n",
        "          edgecolors='black', linewidths=2.5)\n",
        "\n",
        "# Add baseline reference line\n",
        "baseline_acc = rfe_df.iloc[0]['accuracy_mean']\n",
        "ax.axhline(y=baseline_acc, color='gray', linestyle=':', linewidth=2,\n",
        "          label=f'Baseline: {baseline_acc:.2f}% ({rfe_df.iloc[0][\"n_features\"]} features)')\n",
        "\n",
        "# Styling\n",
        "ax.set_xlabel('Number of Features', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
        "ax.set_title('Recursive Feature Elimination: Model Performance vs Feature Count',\n",
        "            fontsize=16, fontweight='bold', pad=20)\n",
        "ax.legend(fontsize=12, loc='best', frameon=True, shadow=True)\n",
        "ax.grid(True, alpha=0.3, linestyle='--', linewidth=1)\n",
        "ax.invert_xaxis()\n",
        "\n",
        "# Add text box with summary\n",
        "textstr = f'Feature Reduction: {rfe_df.iloc[0][\"n_features\"]} â†’ {rfe_df.loc[best_idx, \"n_features\"]}\\n'\n",
        "textstr += f'Reduction: {(1 - rfe_df.loc[best_idx, \"n_features\"]/rfe_df.iloc[0][\"n_features\"])*100:.1f}%\\n'\n",
        "textstr += f'Accuracy Change: {rfe_df.loc[best_idx, \"accuracy_mean\"] - baseline_acc:+.2f}%'\n",
        "props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
        "ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=11,\n",
        "       verticalalignment='top', bbox=props)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('rfe_for_thesis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"âœ… Saved: rfe_for_thesis.png (publication-ready)\")\n",
        "\n",
        "# ========================================\n",
        "# FIGURE 3: DETAILED STATISTICS TABLE\n",
        "# ========================================\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, max(6, len(rfe_df)*0.4)))\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "\n",
        "# Create table data\n",
        "table_data = []\n",
        "table_data.append(['Iteration', 'Features', 'Accuracy (%)', 'Std Dev (%)', 'Drop (%)'])\n",
        "\n",
        "for idx, row in rfe_df.iterrows():\n",
        "    iteration_marker = ''\n",
        "    if idx == best_idx:\n",
        "        iteration_marker = ' â­ OPTIMAL'\n",
        "    elif idx == len(rfe_df) - 1:\n",
        "        iteration_marker = ' ðŸ›‘ STOPPED'\n",
        "\n",
        "    table_data.append([\n",
        "        f\"{int(row['iteration'])}{iteration_marker}\",\n",
        "        f\"{int(row['n_features'])}\",\n",
        "        f\"{row['accuracy_mean']:.2f}\",\n",
        "        f\"{row['accuracy_std']:.2f}\",\n",
        "        f\"{row['drop_from_baseline']:.2f}\"\n",
        "    ])\n",
        "\n",
        "table = ax.table(cellText=table_data, cellLoc='center', loc='center',\n",
        "                colWidths=[0.15, 0.15, 0.2, 0.2, 0.15])\n",
        "\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1, 2)\n",
        "\n",
        "# Style header row\n",
        "for i in range(5):\n",
        "    cell = table[(0, i)]\n",
        "    cell.set_facecolor('#4ECDC4')\n",
        "    cell.set_text_props(weight='bold', color='white')\n",
        "\n",
        "# Highlight optimal row\n",
        "if best_idx < len(table_data) - 1:\n",
        "    for i in range(5):\n",
        "        cell = table[(best_idx + 1, i)]\n",
        "        cell.set_facecolor('#FFD700')\n",
        "        cell.set_text_props(weight='bold')\n",
        "\n",
        "# Highlight stopped row\n",
        "for i in range(5):\n",
        "    cell = table[(len(table_data) - 1, i)]\n",
        "    cell.set_facecolor('#FFB6B6')\n",
        "\n",
        "plt.title('RFE Detailed Results Table', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.savefig('rfe_results_table.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"âœ… Saved: rfe_results_table.png\")\n",
        "\n",
        "# ========================================\n",
        "# SAVE NUMERICAL RESULTS\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING RFE NUMERICAL RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save to CSV\n",
        "rfe_df.to_csv('rfe_results_detailed.csv', index=False)\n",
        "print(\"âœ… Saved: rfe_results_detailed.csv\")\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nðŸ“Š RFE Summary Statistics:\")\n",
        "print(f\"  Starting features: {rfe_df.iloc[0]['n_features']}\")\n",
        "print(f\"  Optimal features: {rfe_df.loc[best_idx, 'n_features']}\")\n",
        "print(f\"  Final features: {rfe_df.iloc[-1]['n_features']}\")\n",
        "print(f\"  Feature reduction: {(1 - rfe_df.loc[best_idx, 'n_features']/rfe_df.iloc[0]['n_features'])*100:.1f}%\")\n",
        "print(f\"\\n  Starting accuracy: {rfe_df.iloc[0]['accuracy_mean']:.2f}%\")\n",
        "print(f\"  Optimal accuracy: {rfe_df.loc[best_idx, 'accuracy_mean']:.2f}%\")\n",
        "print(f\"  Accuracy change: {rfe_df.loc[best_idx, 'accuracy_mean'] - rfe_df.iloc[0]['accuracy_mean']:+.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… RFE VISUALIZATION COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nðŸ“ Files Created:\")\n",
        "print(\"  1. rfe_comprehensive_analysis.png - 4-panel detailed analysis\")\n",
        "print(\"  2. rfe_for_thesis.png - Clean publication-ready plot\")\n",
        "print(\"  3. rfe_results_table.png - Detailed results table\")\n",
        "print(\"  4. rfe_results_detailed.csv - Numerical data\")\n"
      ],
      "metadata": {
        "id": "O3TY96X43F8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 2: TRAIN WITH SELECTED FEATURES\n",
        "# ========================================\n",
        "selected_bands = ee.List(rfe_selected_features)\n",
        "\n",
        "# Train classifier with SELECTED features\n",
        "classifier_selected = ee.Classifier.smileRandomForest(\n",
        "    numberOfTrees=best_params['numberOfTrees'],\n",
        "    variablesPerSplit=best_params['variablesPerSplit'],\n",
        "    minLeafPopulation=best_params['minLeafPopulation'],\n",
        "    bagFraction=best_params['bagFraction'],\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "trained_model_selected = classifier_selected.train(\n",
        "    features=training_set,\n",
        "    classProperty='class',\n",
        "    inputProperties=selected_bands  # Only selected features!\n",
        ")\n",
        "\n",
        "print(\"âœ… Model trained with selected features!\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 3: TEST WITH SELECTED FEATURES - COMPREHENSIVE METRICS\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEST ON HELD-OUT TEST SET - COMPREHENSIVE EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_set = split_data['test']\n",
        "\n",
        "print(f\"\\nTesting on {test_set.size().getInfo()} held-out samples...\")\n",
        "print(f\"Using {len(rfe_selected_features)} RFE-selected features\")\n",
        "\n",
        "# Classify test set with selected features\n",
        "test_predictions_selected = test_set.classify(trained_model_selected)\n",
        "\n",
        "# Get metrics\n",
        "error_matrix_selected = test_predictions_selected.errorMatrix('class', 'classification')\n",
        "test_accuracy_selected = error_matrix_selected.accuracy().getInfo()\n",
        "test_kappa_selected = error_matrix_selected.kappa().getInfo()\n",
        "\n",
        "# Confusion matrix\n",
        "cm_array_selected = error_matrix_selected.array().getInfo()\n",
        "tn, fp = cm_array_selected[0][0], cm_array_selected[0][1]\n",
        "fn, tp = cm_array_selected[1][0], cm_array_selected[1][1]\n",
        "\n",
        "# ========================================\n",
        "# BASIC METRICS\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"BASIC METRICS\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "print(f\"\\nâœ… Overall Performance:\")\n",
        "print(f\"  Accuracy: {test_accuracy_selected*100:.2f}%\")\n",
        "print(f\"  Kappa: {test_kappa_selected:.3f}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Confusion Matrix:\")\n",
        "print(f\"           Predicted Presence  Predicted Absence\")\n",
        "print(f\"  Actual Presence    {tn:5d}            {fp:5d}\")\n",
        "print(f\"  Actual Absence     {fn:5d}            {tp:5d}\")\n",
        "\n",
        "# ========================================\n",
        "# PER-CLASS METRICS (EXPANDED)\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"PER-CLASS METRICS\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Calculate total samples and per-class support\n",
        "total_samples = tn + fp + fn + tp\n",
        "presence_samples = tn + fp\n",
        "absence_samples = fn + tp\n",
        "\n",
        "# Presence (Class 0) metrics\n",
        "presence_precision = tn / (tn + fn) if (tn + fn) > 0 else 0  # User's Accuracy\n",
        "presence_recall = tn / (tn + fp) if (tn + fp) > 0 else 0     # Producer's Accuracy\n",
        "presence_f1 = 2 * (presence_precision * presence_recall) / (presence_precision + presence_recall) if (presence_precision + presence_recall) > 0 else 0\n",
        "presence_specificity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "# Commission and Omission errors for Presence\n",
        "presence_commission_error = 1 - presence_precision\n",
        "presence_omission_error = 1 - presence_recall\n",
        "\n",
        "print(f\"\\n  ðŸ“ PRESENCE (Class 0):\")\n",
        "print(f\"    Support: {presence_samples} samples ({presence_samples/total_samples*100:.1f}%)\")\n",
        "print(f\"    Precision (User's Accuracy):     {presence_precision:.3f} ({presence_precision*100:.1f}%)\")\n",
        "print(f\"    Recall (Producer's Accuracy):    {presence_recall:.3f} ({presence_recall*100:.1f}%)\")\n",
        "print(f\"    F1-Score:                        {presence_f1:.3f}\")\n",
        "print(f\"    Specificity:                     {presence_specificity:.3f}\")\n",
        "print(f\"    Commission Error:                {presence_commission_error:.3f} ({presence_commission_error*100:.1f}%)\")\n",
        "print(f\"    Omission Error:                  {presence_omission_error:.3f} ({presence_omission_error*100:.1f}%)\")\n",
        "\n",
        "# Absence (Class 1) metrics\n",
        "absence_precision = tp / (tp + fp) if (tp + fp) > 0 else 0   # User's Accuracy\n",
        "absence_recall = tp / (tp + fn) if (tp + fn) > 0 else 0      # Producer's Accuracy\n",
        "absence_f1 = 2 * (absence_precision * absence_recall) / (absence_precision + absence_recall) if (absence_precision + absence_recall) > 0 else 0\n",
        "absence_specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "# Commission and Omission errors for Absence\n",
        "absence_commission_error = 1 - absence_precision\n",
        "absence_omission_error = 1 - absence_recall\n",
        "\n",
        "print(f\"\\n  ðŸ“ ABSENCE (Class 1):\")\n",
        "print(f\"    Support: {absence_samples} samples ({absence_samples/total_samples*100:.1f}%)\")\n",
        "print(f\"    Precision (User's Accuracy):     {absence_precision:.3f} ({absence_precision*100:.1f}%)\")\n",
        "print(f\"    Recall (Producer's Accuracy):    {absence_recall:.3f} ({absence_recall*100:.1f}%)\")\n",
        "print(f\"    F1-Score:                        {absence_f1:.3f}\")\n",
        "print(f\"    Specificity:                     {absence_specificity:.3f}\")\n",
        "print(f\"    Commission Error:                {absence_commission_error:.3f} ({absence_commission_error*100:.1f}%)\")\n",
        "print(f\"    Omission Error:                  {absence_omission_error:.3f} ({absence_omission_error*100:.1f}%)\")\n",
        "\n",
        "# ========================================\n",
        "# OVERALL F1-SCORES\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"OVERALL MODEL F1-SCORES\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Macro F1 (unweighted average)\n",
        "macro_f1 = (presence_f1 + absence_f1) / 2\n",
        "\n",
        "# Weighted F1 (weighted by class support)\n",
        "weighted_f1 = (presence_f1 * presence_samples + absence_f1 * absence_samples) / total_samples\n",
        "\n",
        "print(f\"\\n  ðŸŽ¯ Overall F1-Scores:\")\n",
        "print(f\"    Macro F1 (Unweighted):        {macro_f1:.3f}\")\n",
        "print(f\"      â†’ Simple average: ({presence_f1:.3f} + {absence_f1:.3f}) / 2\")\n",
        "print(f\"      â†’ Treats both classes equally\")\n",
        "\n",
        "print(f\"\\n    Weighted F1 (by support):     {weighted_f1:.3f}\")\n",
        "print(f\"      â†’ Weighted by class size\")\n",
        "print(f\"      â†’ Presence: {presence_samples} samples ({presence_samples/total_samples*100:.1f}%)\")\n",
        "print(f\"      â†’ Absence: {absence_samples} samples ({absence_samples/total_samples*100:.1f}%)\")\n",
        "\n",
        "# ========================================\n",
        "# ADDITIONAL OVERALL METRICS\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ADDITIONAL OVERALL METRICS\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Macro averages (unweighted)\n",
        "macro_precision = (presence_precision + absence_precision) / 2\n",
        "macro_recall = (presence_recall + absence_recall) / 2\n",
        "\n",
        "print(f\"\\n  ðŸ“Š Macro-Averaged Metrics (Unweighted):\")\n",
        "print(f\"    Precision: {macro_precision:.3f}\")\n",
        "print(f\"    Recall:    {macro_recall:.3f}\")\n",
        "print(f\"    F1-Score:  {macro_f1:.3f}\")\n",
        "\n",
        "# Weighted averages (by class support)\n",
        "weighted_precision = (presence_precision * presence_samples + absence_precision * absence_samples) / total_samples\n",
        "weighted_recall = (presence_recall * presence_samples + absence_recall * absence_samples) / total_samples\n",
        "\n",
        "print(f\"\\n  ðŸ“Š Weighted-Averaged Metrics (by support):\")\n",
        "print(f\"    Precision: {weighted_precision:.3f}\")\n",
        "print(f\"    Recall:    {weighted_recall:.3f}\")\n",
        "print(f\"    F1-Score:  {weighted_f1:.3f}\")\n",
        "\n",
        "# Balanced accuracy\n",
        "balanced_accuracy = (presence_recall + absence_recall) / 2\n",
        "\n",
        "print(f\"\\n  âš–ï¸  Balanced Accuracy: {balanced_accuracy:.3f} ({balanced_accuracy*100:.1f}%)\")\n",
        "print(f\"      â†’ Average of per-class recalls\")\n",
        "print(f\"      â†’ Handles class imbalance well\")\n",
        "\n",
        "# Matthews Correlation Coefficient (MCC)\n",
        "import math\n",
        "numerator = (tp * tn) - (fp * fn)\n",
        "denominator = math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "mcc = numerator / denominator if denominator > 0 else 0\n",
        "\n",
        "print(f\"\\n  ðŸ”¢ Matthews Correlation Coefficient (MCC): {mcc:.3f}\")\n",
        "print(f\"      â†’ Range: -1 to +1 (where +1 is perfect)\")\n",
        "print(f\"      â†’ Considers all confusion matrix elements\")\n",
        "\n",
        "# ========================================\n",
        "# ERROR ANALYSIS\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ERROR ANALYSIS\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "total_errors = fp + fn\n",
        "error_rate = total_errors / total_samples\n",
        "\n",
        "print(f\"\\n  âŒ Overall Errors:\")\n",
        "print(f\"    Total errors: {total_errors} out of {total_samples} samples\")\n",
        "print(f\"    Error rate: {error_rate:.3f} ({error_rate*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n  ðŸ“Š Error Breakdown:\")\n",
        "print(f\"    False Positives (FP): {fp}\")\n",
        "print(f\"      â†’ Absence incorrectly predicted as Presence\")\n",
        "print(f\"      â†’ {fp/total_samples*100:.1f}% of all samples\")\n",
        "\n",
        "print(f\"\\n    False Negatives (FN): {fn}\")\n",
        "print(f\"      â†’ Presence incorrectly predicted as Absence\")\n",
        "print(f\"      â†’ {fn/total_samples*100:.1f}% of all samples\")\n",
        "\n",
        "print(f\"\\n  âœ… Correct Predictions:\")\n",
        "print(f\"    True Negatives (TN): {tn} (Presence correctly predicted)\")\n",
        "print(f\"    True Positives (TP): {tp} (Absence correctly predicted)\")\n",
        "print(f\"    Total correct: {tn + tp} ({(tn+tp)/total_samples*100:.1f}%)\")\n",
        "\n",
        "# ========================================\n",
        "# INTERPRETATION\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"INTERPRETATION\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# F1 comparison\n",
        "print(f\"\\n  ðŸ“Š F1-Score Analysis:\")\n",
        "f1_diff = abs(macro_f1 - weighted_f1)\n",
        "if f1_diff < 0.01:\n",
        "    print(f\"    âœ… Macro and Weighted F1 are nearly identical (Î” = {f1_diff:.4f})\")\n",
        "    print(f\"       â†’ Model performs consistently across classes\")\n",
        "elif weighted_f1 > macro_f1:\n",
        "    print(f\"    ðŸ“Š Weighted F1 > Macro F1 (Î” = {weighted_f1 - macro_f1:.3f})\")\n",
        "    print(f\"       â†’ Model performs better on larger class (Absence)\")\n",
        "else:\n",
        "    print(f\"    ðŸ“Š Macro F1 > Weighted F1 (Î” = {macro_f1 - weighted_f1:.3f})\")\n",
        "    print(f\"       â†’ Model performs better on smaller class (Presence)\")\n",
        "\n",
        "# Kappa interpretation\n",
        "print(f\"\\n  ðŸ“Š Cohen's Kappa Interpretation:\")\n",
        "if test_kappa_selected > 0.80:\n",
        "    print(f\"    ðŸŒŸ Excellent agreement (Îº = {test_kappa_selected:.3f})\")\n",
        "elif test_kappa_selected > 0.60:\n",
        "    print(f\"    âœ… Substantial agreement (Îº = {test_kappa_selected:.3f})\")\n",
        "elif test_kappa_selected > 0.40:\n",
        "    print(f\"    ðŸ‘ Moderate agreement (Îº = {test_kappa_selected:.3f})\")\n",
        "elif test_kappa_selected > 0.20:\n",
        "    print(f\"    âš ï¸  Fair agreement (Îº = {test_kappa_selected:.3f})\")\n",
        "else:\n",
        "    print(f\"    âŒ Poor agreement (Îº = {test_kappa_selected:.3f})\")\n",
        "\n",
        "# Balance analysis\n",
        "print(f\"\\n  âš–ï¸  Class Balance Analysis:\")\n",
        "print(f\"    Presence recall vs Absence recall: {presence_recall:.3f} vs {absence_recall:.3f}\")\n",
        "recall_diff = abs(presence_recall - absence_recall)\n",
        "if recall_diff < 0.05:\n",
        "    print(f\"    âœ… Balanced performance across classes (Î” = {recall_diff:.3f})\")\n",
        "elif presence_recall > absence_recall:\n",
        "    print(f\"    ðŸ“Š Better at detecting Presence (Î” = {recall_diff:.3f})\")\n",
        "else:\n",
        "    print(f\"    ðŸ“Š Better at detecting Absence (Î” = {recall_diff:.3f})\")\n",
        "\n",
        "# ========================================\n",
        "# SAVE COMPREHENSIVE METRICS\n",
        "# ========================================\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"SAVING METRICS\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "comprehensive_metrics = {\n",
        "    'model_info': {\n",
        "        'n_features': len(rfe_selected_features),\n",
        "        'test_samples': int(total_samples),\n",
        "        'presence_samples': int(presence_samples),\n",
        "        'absence_samples': int(absence_samples)\n",
        "    },\n",
        "    'overall_metrics': {\n",
        "        'accuracy': float(test_accuracy_selected),\n",
        "        'kappa': float(test_kappa_selected),\n",
        "        'balanced_accuracy': float(balanced_accuracy),\n",
        "        'mcc': float(mcc),\n",
        "        'error_rate': float(error_rate)\n",
        "    },\n",
        "    'overall_f1_scores': {\n",
        "        'macro_f1': float(macro_f1),\n",
        "        'weighted_f1': float(weighted_f1)\n",
        "    },\n",
        "    'macro_averages': {\n",
        "        'precision': float(macro_precision),\n",
        "        'recall': float(macro_recall),\n",
        "        'f1_score': float(macro_f1)\n",
        "    },\n",
        "    'weighted_averages': {\n",
        "        'precision': float(weighted_precision),\n",
        "        'recall': float(weighted_recall),\n",
        "        'f1_score': float(weighted_f1)\n",
        "    },\n",
        "    'confusion_matrix': {\n",
        "        'tn': int(tn),\n",
        "        'fp': int(fp),\n",
        "        'fn': int(fn),\n",
        "        'tp': int(tp)\n",
        "    },\n",
        "    'presence_class_0': {\n",
        "        'support': int(presence_samples),\n",
        "        'precision_users_accuracy': float(presence_precision),\n",
        "        'recall_producers_accuracy': float(presence_recall),\n",
        "        'f1_score': float(presence_f1),\n",
        "        'specificity': float(presence_specificity),\n",
        "        'commission_error': float(presence_commission_error),\n",
        "        'omission_error': float(presence_omission_error)\n",
        "    },\n",
        "    'absence_class_1': {\n",
        "        'support': int(absence_samples),\n",
        "        'precision_users_accuracy': float(absence_precision),\n",
        "        'recall_producers_accuracy': float(absence_recall),\n",
        "        'f1_score': float(absence_f1),\n",
        "        'specificity': float(absence_specificity),\n",
        "        'commission_error': float(absence_commission_error),\n",
        "        'omission_error': float(absence_omission_error)\n",
        "    },\n",
        "    'error_analysis': {\n",
        "        'total_errors': int(total_errors),\n",
        "        'false_positives': int(fp),\n",
        "        'false_negatives': int(fn),\n",
        "        'true_negatives': int(tn),\n",
        "        'true_positives': int(tp)\n",
        "    }\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('comprehensive_test_metrics.json', 'w') as f:\n",
        "    json.dump(comprehensive_metrics, f, indent=2)\n",
        "\n",
        "print(\"\\nâœ… Saved: comprehensive_test_metrics.json\")\n",
        "\n",
        "# Save as readable CSV\n",
        "metrics_summary_df = pd.DataFrame([\n",
        "    {'Category': 'Overall', 'Metric': 'Accuracy', 'Value': f\"{test_accuracy_selected*100:.2f}%\"},\n",
        "    {'Category': 'Overall', 'Metric': 'Cohen\\'s Kappa', 'Value': f\"{test_kappa_selected:.3f}\"},\n",
        "    {'Category': 'Overall', 'Metric': 'Balanced Accuracy', 'Value': f\"{balanced_accuracy*100:.2f}%\"},\n",
        "    {'Category': 'Overall', 'Metric': 'MCC', 'Value': f\"{mcc:.3f}\"},\n",
        "    {'Category': 'Overall', 'Metric': 'Error Rate', 'Value': f\"{error_rate*100:.1f}%\"},\n",
        "    {'Category': 'Overall F1', 'Metric': 'Macro F1', 'Value': f\"{macro_f1:.3f}\"},\n",
        "    {'Category': 'Overall F1', 'Metric': 'Weighted F1', 'Value': f\"{weighted_f1:.3f}\"},\n",
        "    {'Category': 'Presence', 'Metric': 'Precision', 'Value': f\"{presence_precision:.3f}\"},\n",
        "    {'Category': 'Presence', 'Metric': 'Recall', 'Value': f\"{presence_recall:.3f}\"},\n",
        "    {'Category': 'Presence', 'Metric': 'F1-Score', 'Value': f\"{presence_f1:.3f}\"},\n",
        "    {'Category': 'Presence', 'Metric': 'Specificity', 'Value': f\"{presence_specificity:.3f}\"},\n",
        "    {'Category': 'Absence', 'Metric': 'Precision', 'Value': f\"{absence_precision:.3f}\"},\n",
        "    {'Category': 'Absence', 'Metric': 'Recall', 'Value': f\"{absence_recall:.3f}\"},\n",
        "    {'Category': 'Absence', 'Metric': 'F1-Score', 'Value': f\"{absence_f1:.3f}\"},\n",
        "    {'Category': 'Absence', 'Metric': 'Specificity', 'Value': f\"{absence_specificity:.3f}\"},\n",
        "    {'Category': 'Macro Avg', 'Metric': 'Precision', 'Value': f\"{macro_precision:.3f}\"},\n",
        "    {'Category': 'Macro Avg', 'Metric': 'Recall', 'Value': f\"{macro_recall:.3f}\"},\n",
        "    {'Category': 'Macro Avg', 'Metric': 'F1-Score', 'Value': f\"{macro_f1:.3f}\"},\n",
        "    {'Category': 'Weighted Avg', 'Metric': 'Precision', 'Value': f\"{weighted_precision:.3f}\"},\n",
        "    {'Category': 'Weighted Avg', 'Metric': 'Recall', 'Value': f\"{weighted_recall:.3f}\"},\n",
        "    {'Category': 'Weighted Avg', 'Metric': 'F1-Score', 'Value': f\"{weighted_f1:.3f}\"},\n",
        "])\n",
        "\n",
        "metrics_summary_df.to_csv('test_metrics_summary.csv', index=False)\n",
        "print(\"âœ… Saved: test_metrics_summary.csv\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"âœ… COMPREHENSIVE TEST EVALUATION COMPLETE!\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Quick Summary:\")\n",
        "print(f\"   Test Accuracy:  {test_accuracy_selected*100:.2f}%\")\n",
        "print(f\"   Kappa:          {test_kappa_selected:.3f}\")\n",
        "print(f\"   Macro F1:       {macro_f1:.3f}\")\n",
        "print(f\"   Weighted F1:    {weighted_f1:.3f}\")\n",
        "print(f\"   Balanced Acc:   {balanced_accuracy*100:.1f}%\")"
      ],
      "metadata": {
        "id": "NWuZ5E-f3fEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# EXTRACT FEATURE IMPORTANCE\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE IMPORTANCE EXTRACTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nExtracting feature importance from trained model...\")\n",
        "\n",
        "# Get model explanation (includes feature importance)\n",
        "model_explanation = trained_model_selected.explain().getInfo()\n",
        "\n",
        "# Extract variable importance\n",
        "if 'importance' in model_explanation:\n",
        "    importance_dict = model_explanation['importance']\n",
        "\n",
        "    # Convert to pandas DataFrame\n",
        "    importance_df = pd.DataFrame([\n",
        "        {'band': band, 'importance': importance_dict[band]}\n",
        "        for band in importance_dict.keys()\n",
        "    ])\n",
        "\n",
        "    # Sort by importance (descending)\n",
        "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
        "    importance_df['cumulative_importance'] = importance_df['importance'].cumsum()\n",
        "    importance_df['percent_importance'] = (importance_df['importance'] / importance_df['importance'].sum()) * 100\n",
        "    importance_df['cumulative_percent'] = importance_df['percent_importance'].cumsum()\n",
        "\n",
        "    print(f\"\\nâœ… Extracted importance for {len(importance_df)} features\")\n",
        "\n",
        "    # Show top 10 most important features\n",
        "    print(f\"\\nðŸ“Š Top 10 Most Important Features:\")\n",
        "    print(importance_df.head(10)[['band', 'importance', 'percent_importance', 'cumulative_percent']].to_string(index=False))\n",
        "\n",
        "    # Summary statistics\n",
        "    print(f\"\\nðŸ“ˆ Importance Summary:\")\n",
        "    print(f\"  Top 5 features: {importance_df.head(5)['cumulative_percent'].iloc[-1]:.2f}% of total importance\")\n",
        "    print(f\"  Top 10 features: {importance_df.head(10)['cumulative_percent'].iloc[-1]:.2f}% of total importance\")\n",
        "    print(f\"  Top 20 features: {importance_df.head(20)['cumulative_percent'].iloc[-1]:.2f}% of total importance\")\n",
        "\n",
        "    # Save to CSV\n",
        "    importance_df.to_csv('feature_importance_train_test_model.csv', index=False)\n",
        "    print(f\"\\nâœ… Feature importance saved to 'feature_importance_train_test_model.csv'\")\n",
        "\n",
        "    # ========================================\n",
        "    # VISUALIZE FEATURE IMPORTANCE\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\\nCreating feature importance visualizations...\")\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Plot 1: Top 20 features\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    top_10 = importance_df.head(10)\n",
        "    axes[0].barh(range(len(top_10)), top_10['importance'])\n",
        "    axes[0].set_yticks(range(len(top_10)))\n",
        "    axes[0].set_yticklabels(top_10['band'])\n",
        "    axes[0].set_xlabel('Importance', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_ylabel('Feature (NDVI Band)', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_title('Top 10 Most Important Features', fontsize=13, fontweight='bold')\n",
        "    axes[0].invert_yaxis()\n",
        "    axes[0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "    # Plot 2: Cumulative importance\n",
        "    axes[1].plot(range(1, len(importance_df) + 1), importance_df['cumulative_percent'],\n",
        "                linewidth=2, marker='o', markersize=4, color='#2E86AB')\n",
        "    axes[1].axhline(y=50, color='r', linestyle='--', linewidth=2, label='50% threshold')\n",
        "    axes[1].axhline(y=80, color='orange', linestyle='--', linewidth=2, label='80% threshold')\n",
        "    axes[1].axhline(y=95, color='green', linestyle='--', linewidth=2, label='95% threshold')\n",
        "    axes[1].set_xlabel('Number of Features', fontsize=12, fontweight='bold')\n",
        "    axes[1].set_ylabel('Cumulative Importance (%)', fontsize=12, fontweight='bold')\n",
        "    axes[1].set_title('Cumulative Feature Importance', fontsize=13, fontweight='bold')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance_train_test_model.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"âœ… Saved: feature_importance_train_test_model.png\")\n",
        "\n",
        "    # Most important time periods\n",
        "    print(f\"\\nðŸ—“ï¸  Most Important Time Periods:\")\n",
        "    for idx, row in importance_df.head(10).iterrows():\n",
        "        print(f\"  {row['band']}: {row['percent_importance']:.2f}% importance\")\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸  Could not extract feature importance\")\n",
        "    print(\"Model explanation structure:\", model_explanation)\n",
        "\n",
        "# ========================================\n",
        "# CREATE CLASSIFICATION MAP\n",
        "# ========================================\n",
        "\n",
        "# âœ… SELECT ONLY THE RFE-SELECTED FEATURES FROM THE IMAGE\n",
        "selected_bands_image = filtered_image.select(rfe_selected_features)\n",
        "\n",
        "print(f\"\\nApplying trained model to entire study area...\")\n",
        "print(f\"  Using all {len(temporal_bands.getInfo())} features\")\n",
        "\n",
        "# Apply the trained model to the SELECTED-FEATURES image\n",
        "classified = selected_bands_image.classify(trained_model_selected)\n",
        "\n",
        "print(\"âœ… Classification complete!\")\n",
        "\n",
        "# ========================================\n",
        "# CALCULATE CLASSIFICATION STATISTICS\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CLASSIFICATION STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nCalculating area statistics...\")\n",
        "\n",
        "# Calculate pixel counts\n",
        "pixel_counts = classified.reduceRegion(\n",
        "    reducer=ee.Reducer.frequencyHistogram(),\n",
        "    geometry=SLPP,\n",
        "    scale=10,\n",
        "    maxPixels=1e9\n",
        ").getInfo()\n",
        "\n",
        "# Extract counts\n",
        "class_counts = pixel_counts.get('classification', {})\n",
        "\n",
        "if '0' in class_counts and '1' in class_counts:\n",
        "    presence_pixels = class_counts['0']\n",
        "    absence_pixels = class_counts['1']\n",
        "    total_pixels = presence_pixels + absence_pixels\n",
        "\n",
        "    # Calculate areas (10m resolution = 100 mÂ² per pixel)\n",
        "    pixel_area = 100  # mÂ²\n",
        "    presence_area_m2 = presence_pixels * pixel_area\n",
        "    absence_area_m2 = absence_pixels * pixel_area\n",
        "\n",
        "    # Convert to hectares\n",
        "    presence_area_ha = presence_area_m2 / 10000\n",
        "    absence_area_ha = absence_area_m2 / 10000\n",
        "    total_area_ha = (presence_area_m2 + absence_area_m2) / 10000\n",
        "\n",
        "    # Calculate percentages\n",
        "    presence_percent = (presence_pixels / total_pixels) * 100\n",
        "    absence_percent = (absence_pixels / total_pixels) * 100\n",
        "\n",
        "    print(f\"\\nðŸ“Š Classification Summary:\")\n",
        "    print(f\"\\n  Presence (Class 0):\")\n",
        "    print(f\"    Pixels: {presence_pixels:,}\")\n",
        "    print(f\"    Area: {presence_area_ha:,.2f} hectares ({presence_area_m2:,.0f} mÂ²)\")\n",
        "    print(f\"    Percentage: {presence_percent:.2f}%\")\n",
        "\n",
        "    print(f\"\\n  Absence (Class 1):\")\n",
        "    print(f\"    Pixels: {absence_pixels:,}\")\n",
        "    print(f\"    Area: {absence_area_ha:,.2f} hectares ({absence_area_m2:,.0f} mÂ²)\")\n",
        "    print(f\"    Percentage: {absence_percent:.2f}%\")\n",
        "\n",
        "    print(f\"\\n  Total Classified Area:\")\n",
        "    print(f\"    Pixels: {total_pixels:,}\")\n",
        "    print(f\"    Area: {total_area_ha:,.2f} hectares\")\n",
        "\n",
        "    # Save statistics\n",
        "    classification_stats = {\n",
        "        'presence': {\n",
        "            'pixels': int(presence_pixels),\n",
        "            'area_hectares': float(presence_area_ha),\n",
        "            'area_m2': float(presence_area_m2),\n",
        "            'percentage': float(presence_percent)\n",
        "        },\n",
        "        'absence': {\n",
        "            'pixels': int(absence_pixels),\n",
        "            'area_hectares': float(absence_area_ha),\n",
        "            'area_m2': float(absence_area_m2),\n",
        "            'percentage': float(absence_percent)\n",
        "        },\n",
        "        'total': {\n",
        "            'pixels': int(total_pixels),\n",
        "            'area_hectares': float(total_area_ha)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    import json\n",
        "    with open('classification_statistics.json', 'w') as f:\n",
        "        json.dump(classification_stats, f, indent=2)\n",
        "\n",
        "    print(f\"\\nâœ… Statistics saved to 'classification_statistics.json'\")\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸  Could not calculate statistics. Check classification results.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Em_sKQ071PYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qx5DVGYPjP-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# VISUALIZE CLASSIFICATION MAP - COMPLETE\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATING INTERACTIVE MAP\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import geemap\n",
        "\n",
        "# Create map\n",
        "Map = geemap.Map()\n",
        "Map.centerObject(SLPP, 12)\n",
        "\n",
        "print(\"\\nðŸ“ Adding layers to map...\")\n",
        "\n",
        "# Add boundary\n",
        "Map.addLayer(SLPP, {'color': 'yellow'}, 'SLPP Boundary')\n",
        "print(\"  âœ… Added: SLPP Boundary\")\n",
        "\n",
        "# Add classification\n",
        "Map.addLayer(\n",
        "    classified,\n",
        "    {\n",
        "        'min': 0,\n",
        "        'max': 1,\n",
        "        'palette': ['#FF6B6B', '#4ECDC4']\n",
        "    },\n",
        "    'Classification (RFE Model)',\n",
        "    True\n",
        ")\n",
        "print(\"  âœ… Added: Classification layer\")\n",
        "\n",
        "# Add NDVI example\n",
        "Map.addLayer(\n",
        "    filtered_image.select('t30'),\n",
        "    {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']},\n",
        "    'NDVI (t30)',\n",
        "    False\n",
        ")\n",
        "print(\"  âœ… Added: NDVI example (hidden)\")\n",
        "\n",
        "# Add training points\n",
        "Map.addLayer(\n",
        "    training_set.filter(ee.Filter.eq('class', 0)),\n",
        "    {'color': 'red'},\n",
        "    'Training Points - Presence',\n",
        "    False\n",
        ")\n",
        "Map.addLayer(\n",
        "    training_set.filter(ee.Filter.eq('class', 1)),\n",
        "    {'color': 'blue'},\n",
        "    'Training Points - Absence',\n",
        "    False\n",
        ")\n",
        "print(\"  âœ… Added: Training points (hidden)\")\n",
        "\n",
        "# Add test points\n",
        "Map.addLayer(\n",
        "    test_set.filter(ee.Filter.eq('class', 0)),\n",
        "    {'color': 'orange'},\n",
        "    'Test Points - Presence',\n",
        "    False\n",
        ")\n",
        "Map.addLayer(\n",
        "    test_set.filter(ee.Filter.eq('class', 1)),\n",
        "    {'color': 'cyan'},\n",
        "    'Test Points - Absence',\n",
        "    False\n",
        ")\n",
        "print(\"  âœ… Added: Test points (hidden)\")\n",
        "\n",
        "# Add legend\n",
        "legend_dict = {\n",
        "    'Presence (Class 0)': '#FF6B6B',\n",
        "    'Absence (Class 1)': '#4ECDC4'\n",
        "}\n",
        "Map.add_legend(legend_title='Classification', legend_dict=legend_dict)\n",
        "print(\"  âœ… Added: Legend\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ—ºï¸  MAP READY!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nðŸ“ Map contains:\")\n",
        "print(\"  - SLPP Boundary (yellow outline)\")\n",
        "print(\"  - Classification (red=Presence, teal=Absence)\")\n",
        "print(\"  - NDVI band example (toggle on in layers)\")\n",
        "print(\"  - Training points (toggle on in layers)\")\n",
        "print(\"  - Test points (toggle on in layers)\")\n",
        "\n",
        "# Save as HTML\n",
        "print(\"\\nðŸ’¾ Saving map as HTML file...\")\n",
        "Map.to_html('classification_map.html')\n",
        "print(\"âœ… Saved to 'classification_map.html'\")\n",
        "\n",
        "# Display in notebook\n",
        "print(\"\\nðŸ—ºï¸  Displaying map below...\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# CRITICAL: This must be the LAST line to display the map\n",
        "display(Map)"
      ],
      "metadata": {
        "id": "x8TNSzs4jQtZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}